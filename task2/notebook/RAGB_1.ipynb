{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Zv_lGErWLFMk",
        "outputId": "453cbb13-3d0c-4e67-c3c1-5282adfb703a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan 18 13:23:13 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA A100-SXM4-40GB          Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   31C    P0             44W /  400W |       0MiB /  40960MiB |      0%      Default |\n",
            "|                                         |                        |             Disabled |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "AeUkjqRzLkju",
        "outputId": "54c84275-4eb0-47d6-c2a6-327b84d95ef7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.9/87.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m126.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m149.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.9/474.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m355.0/355.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.0/183.0 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.0/111.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/45.4 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m125.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m98.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.2/96.2 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m137.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m109.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.4/72.4 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m74.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.0/388.0 kB\u001b[0m \u001b[31m38.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m285.4/285.4 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.0/149.0 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.9/224.9 kB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m112.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m821.6/821.6 kB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m959.8/959.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip -q install -U transformers accelerate sentencepiece pandas tqdm vllm huggingface_hub\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "994dcb23cb954171b1e1b38202b91de8",
            "5b5ad4b5490045cba76d868d897411fe",
            "105bc2eead9f4d9f890c011a0d7128cd",
            "ffe32e45e135464cbcaa857368cae659",
            "9a6a6d4aa1cf446286e5d3a464383574",
            "889fe31bd6834308b74e2df51ab75f34",
            "44fe089231b745ea86346a63471fa859",
            "bab1faec9af74f39bca7e74ed441dbb9",
            "22050508dd884aecbc21b7168ca9f428",
            "247df6876b154d1fa2f32fbd80961a3f",
            "0182461a90f14207b62fc7fd013ddf13",
            "b0a0a6e9782f4b4f842c43c31603851e",
            "cce1bf37baf348559beeb8a9f02c8050",
            "ac5bee6870b6414ab3767940b67edc44",
            "f4644f215d7043479f45aad032ba7517",
            "b9f83c676a424002b152e664df216a97",
            "0717889b10f24f25bcf4d712f20a1e95",
            "c7b9dd1528ba4cbe983b9cced52c1bfc",
            "a466f895720e4797b729c196b41bc4d6",
            "06117d9f785945629c94505af21cbd05"
          ]
        },
        "id": "bpPKLsTUDVmD",
        "outputId": "74e072bb-3be2-459c-972b-09979d0d91b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "994dcb23cb954171b1e1b38202b91de8"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "YH66h9-wMIwj",
        "outputId": "071d3fc6-31d9-445c-b9ba-f71118ca81aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'RGB'...\n",
            "remote: Enumerating objects: 50, done.\u001b[K\n",
            "remote: Counting objects: 100% (50/50), done.\u001b[K\n",
            "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
            "remote: Total 50 (delta 22), reused 34 (delta 10), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (50/50), 8.16 MiB | 11.59 MiB/s, done.\n",
            "Resolving deltas: 100% (22/22), done.\n",
            "config\tenv.sh\t   fact_evalue.py  models     reject_evalue.py\n",
            "data\tevalue.py  LICENSE.txt\t   readme.md\n",
            "en_fact.json  en.json\t      zh_fact.json  zh.json\n",
            "en_int.json   en_refine.json  zh_int.json   zh_refine.json\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/chen700564/RGB\n",
        "!ls RGB\n",
        "!ls RGB/data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile rgb_eval.py\n",
        "import argparse\n",
        "import json\n",
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Dict, List, Optional\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Prompt (Figure 3 from the paper)\n",
        "# -----------------------------\n",
        "SYSTEM_INSTRUCTION_EN = (\n",
        "    \"You are an accurate and reliable AI assistant that can\\n\"\n",
        "    \"answer questions with the help of external documents.\\n\"\n",
        "    \"Please note that external documents may contain noisy\\n\"\n",
        "    \"or factually incorrect information. If the information in\\n\"\n",
        "    \"the document contains the correct answer, you will give\\n\"\n",
        "    \"an accurate answer. If the information in the document\\n\"\n",
        "    \"does not contain the answer, you will generate 'I can not\\n\"\n",
        "    \"answer the question because of the insufficient\\n\"\n",
        "    \"information in documents.' If there are inconsistencies\\n\"\n",
        "    \"with the facts in some of the documents, please generate\\n\"\n",
        "    \"the response 'There are factual errors in the provided\\n\"\n",
        "    \"documents.' and provide the correct answer.\"\n",
        ")\n",
        "\n",
        "USER_TEMPLATE_EN = \"Document:\\n{DOCS}\\n\\nQuestion:\\n{QUERY}\"\n",
        "\n",
        "REJECTION_PHRASE = \"I can not answer the question because of the insufficient information in documents.\"\n",
        "FACT_ERROR_PHRASE = \"There are factual errors in the provided documents.\"\n",
        "\n",
        "\n",
        "def format_docs(docs: List[str]) -> str:\n",
        "    out = []\n",
        "    for i, d in enumerate(docs, 1):\n",
        "        out.append(f\"[Doc {i}] {str(d).strip()}\")\n",
        "    return \"\\n\\n\".join(out)\n",
        "\n",
        "\n",
        "def build_prompt(question: str, docs: List[str]) -> str:\n",
        "    return USER_TEMPLATE_EN.format(DOCS=format_docs(docs), QUERY=question)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Dataset parsing (robust to schema differences)\n",
        "# -----------------------------\n",
        "@dataclass\n",
        "class RGBExample:\n",
        "    qid: str\n",
        "    question: str\n",
        "    answers: List[str]\n",
        "    pos_docs: List[str]\n",
        "    neg_docs: List[str]\n",
        "    need_reject: Optional[int]\n",
        "    is_counterfactual: Optional[int]\n",
        "    raw: Dict[str, Any]\n",
        "\n",
        "\n",
        "def _as_list(x) -> List[Any]:\n",
        "    if x is None:\n",
        "        return []\n",
        "    return x if isinstance(x, list) else [x]\n",
        "\n",
        "\n",
        "def infer_and_parse_examples(path: str) -> List[RGBExample]:\n",
        "    # Support JSONL (one JSON dict per line) and JSON array\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        first = f.read(1)\n",
        "        f.seek(0)\n",
        "        if first == \"[\":\n",
        "            data = json.load(f)\n",
        "        else:\n",
        "            data = []\n",
        "            for line in f:\n",
        "                line = line.strip()\n",
        "                if not line:\n",
        "                    continue\n",
        "                data.append(json.loads(line))\n",
        "\n",
        "    if not isinstance(data, list):\n",
        "        raise ValueError(\"RGB file must decode to a list of examples\")\n",
        "\n",
        "    q_keys = [\"question\", \"query\", \"Q\", \"Question\"]\n",
        "    a_keys = [\"ground_truths\", \"answers\", \"answer\", \"ground_truth\", \"A\"]\n",
        "    pos_keys = [\"positive\", \"pos\", \"positive_docs\", \"pos_docs\"]\n",
        "    neg_keys = [\"negative\", \"neg\", \"negative_docs\", \"neg_docs\"]\n",
        "\n",
        "    reject_keys = [\"need_reject\", \"should_reject\", \"is_reject\", \"reject\"]\n",
        "    cf_keys = [\"is_counterfactual\", \"counterfactual\", \"is_cf\"]\n",
        "\n",
        "    def pick(ex: dict, keys: List[str]) -> Optional[Any]:\n",
        "        for k in keys:\n",
        "            if k in ex:\n",
        "                return ex[k]\n",
        "        return None\n",
        "\n",
        "    def pick_bool(ex: dict, keys: List[str]) -> Optional[int]:\n",
        "        for k in keys:\n",
        "            if k in ex:\n",
        "                v = ex[k]\n",
        "                if isinstance(v, bool):\n",
        "                    return int(v)\n",
        "                if isinstance(v, (int, float)):\n",
        "                    return int(v != 0)\n",
        "                if isinstance(v, str):\n",
        "                    s = v.strip().lower()\n",
        "                    if s in [\"true\", \"yes\", \"1\"]:\n",
        "                        return 1\n",
        "                    if s in [\"false\", \"no\", \"0\"]:\n",
        "                        return 0\n",
        "        return None\n",
        "\n",
        "    def normalize_docs(docs_any) -> List[str]:\n",
        "        docs_any = _as_list(docs_any)\n",
        "        out_docs: List[str] = []\n",
        "        for d in docs_any:\n",
        "            if isinstance(d, str):\n",
        "                out_docs.append(d)\n",
        "            elif isinstance(d, dict):\n",
        "                for dk in [\"content\", \"text\", \"snippet\", \"document\", \"doc\"]:\n",
        "                    if dk in d and isinstance(d[dk], str):\n",
        "                        out_docs.append(d[dk])\n",
        "                        break\n",
        "        return out_docs\n",
        "\n",
        "    out_examples: List[RGBExample] = []\n",
        "    for idx, ex in enumerate(data):\n",
        "        if not isinstance(ex, dict):\n",
        "            continue\n",
        "\n",
        "        q = pick(ex, q_keys)\n",
        "        a = pick(ex, a_keys)\n",
        "        pos = pick(ex, pos_keys)\n",
        "        neg = pick(ex, neg_keys)\n",
        "\n",
        "        question = q if isinstance(q, str) else \"\"\n",
        "\n",
        "        # Flatten answers\n",
        "        answers: List[str] = []\n",
        "        for item in _as_list(a):\n",
        "            if isinstance(item, str):\n",
        "                answers.append(item)\n",
        "            elif isinstance(item, list):\n",
        "                answers.extend([x for x in item if isinstance(x, str)])\n",
        "\n",
        "        pos_docs = normalize_docs(pos)\n",
        "        neg_docs = normalize_docs(neg)\n",
        "\n",
        "        # Fallback if docs stored unlabelled\n",
        "        if not pos_docs and not neg_docs:\n",
        "            for k in [\"documents\", \"docs\", \"contexts\", \"context\"]:\n",
        "                if k in ex:\n",
        "                    neg_docs = normalize_docs(ex[k])\n",
        "                    break\n",
        "\n",
        "        need_reject = pick_bool(ex, reject_keys)\n",
        "        is_counterfactual = pick_bool(ex, cf_keys)\n",
        "\n",
        "        qid = str(ex.get(\"id\", ex.get(\"qid\", idx)))\n",
        "        out_examples.append(\n",
        "            RGBExample(\n",
        "                qid=qid,\n",
        "                question=question,\n",
        "                answers=answers,\n",
        "                pos_docs=pos_docs,\n",
        "                neg_docs=neg_docs,\n",
        "                need_reject=need_reject,\n",
        "                is_counterfactual=is_counterfactual,\n",
        "                raw=ex,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    return out_examples\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Sampling docs for noise experiments\n",
        "# -----------------------------\n",
        "def sample_docs(ex: RGBExample, passage_num: int, noise_rate: float, rng: random.Random) -> List[str]:\n",
        "    n_noise = int(round(passage_num * noise_rate))\n",
        "    n_pos = passage_num - n_noise\n",
        "\n",
        "    def pick(pool: List[str], k: int) -> List[str]:\n",
        "        if k <= 0:\n",
        "            return []\n",
        "        if not pool:\n",
        "            return [\"\"] * k\n",
        "        if len(pool) >= k:\n",
        "            return rng.sample(pool, k)\n",
        "        return [pool[rng.randrange(len(pool))] for _ in range(k)]\n",
        "\n",
        "    docs = pick(ex.pos_docs, n_pos) + pick(ex.neg_docs, n_noise)\n",
        "    rng.shuffle(docs)\n",
        "    return docs\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Model runner\n",
        "# -----------------------------\n",
        "class HFGenerator:\n",
        "    def __init__(self, model_name: str):\n",
        "        self.model_name = model_name\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "\n",
        "        if self.tokenizer.pad_token is None:\n",
        "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
        "\n",
        "        self.model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_name,\n",
        "            torch_dtype=torch.bfloat16 if torch.cuda.is_available() else torch.float32,\n",
        "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
        "        )\n",
        "        self.model.eval()\n",
        "\n",
        "    def generate(\n",
        "        self,\n",
        "        system_text: str,\n",
        "        user_text: str,\n",
        "        max_new_tokens: int,\n",
        "        temperature: float,\n",
        "        top_p: float,\n",
        "        seed: int,\n",
        "    ) -> str:\n",
        "        torch.manual_seed(seed)\n",
        "\n",
        "        messages = [\n",
        "            {\"role\": \"system\", \"content\": system_text},\n",
        "            {\"role\": \"user\", \"content\": user_text},\n",
        "        ]\n",
        "\n",
        "        if hasattr(self.tokenizer, \"apply_chat_template\"):\n",
        "            enc = self.tokenizer.apply_chat_template(\n",
        "                messages,\n",
        "                add_generation_prompt=True,\n",
        "                return_tensors=\"pt\",\n",
        "                return_dict=True,\n",
        "            )\n",
        "            input_ids = enc[\"input_ids\"].to(self.model.device)\n",
        "            attention_mask = enc.get(\"attention_mask\", None)\n",
        "            if attention_mask is None:\n",
        "                attention_mask = torch.ones_like(input_ids, device=self.model.device)\n",
        "            else:\n",
        "                attention_mask = attention_mask.to(self.model.device)\n",
        "        else:\n",
        "            joined = f\"{system_text}\\n\\n{user_text}\\n\\nAnswer:\"\n",
        "            enc = self.tokenizer(joined, return_tensors=\"pt\")\n",
        "            input_ids = enc[\"input_ids\"].to(self.model.device)\n",
        "            attention_mask = enc[\"attention_mask\"].to(self.model.device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            out = self.model.generate(\n",
        "                input_ids=input_ids,\n",
        "                attention_mask=attention_mask,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                do_sample=(temperature > 0),\n",
        "                temperature=temperature if temperature > 0 else None,\n",
        "                top_p=top_p,\n",
        "                pad_token_id=self.tokenizer.pad_token_id,\n",
        "                eos_token_id=self.tokenizer.eos_token_id,\n",
        "            )\n",
        "\n",
        "        gen_ids = out[0][input_ids.shape[-1] :]\n",
        "        text = self.tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "        return text\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# Metrics\n",
        "# -----------------------------\n",
        "def contains_any_answer(gen: str, answers: List[str]) -> bool:\n",
        "    g = gen.lower()\n",
        "    for a in answers:\n",
        "        if a and a.lower() in g:\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "\n",
        "def is_rejection(gen: str) -> bool:\n",
        "    return REJECTION_PHRASE.lower() in gen.lower()\n",
        "\n",
        "\n",
        "def is_error_detected(gen: str) -> bool:\n",
        "    return FACT_ERROR_PHRASE.lower() in gen.lower()\n",
        "\n",
        "\n",
        "def summarize(df: pd.DataFrame, task: str) -> Dict[str, float]:\n",
        "    if len(df) == 0:\n",
        "        return {}\n",
        "\n",
        "    if task in [\"noise\", \"integration\"]:\n",
        "        return {\"accuracy\": float(df[\"correct\"].mean())}\n",
        "\n",
        "    if task == \"rejection\":\n",
        "        # Paper-style: evaluate only where the dataset says we SHOULD reject\n",
        "        if \"need_reject\" in df.columns and df[\"need_reject\"].notna().any():\n",
        "            mask = df[\"need_reject\"] == 1\n",
        "            rej = float(df.loc[mask, \"is_rejection\"].mean()) if mask.any() else float(\"nan\")\n",
        "            false_rej = float(df.loc[~mask, \"is_rejection\"].mean()) if (~mask).any() else float(\"nan\")\n",
        "            return {\"rejection_rate\": rej, \"false_rejection_rate\": false_rej}\n",
        "        return {\"rejection_rate\": float(df[\"is_rejection\"].mean())}\n",
        "\n",
        "    if task == \"counterfactual\":\n",
        "        out: Dict[str, float] = {}\n",
        "\n",
        "        # ACC: no-doc correctness\n",
        "        if \"correct_nodoc\" in df.columns and df[\"correct_nodoc\"].notna().any():\n",
        "            out[\"accuracy_nodoc\"] = float(df[\"correct_nodoc\"].mean())\n",
        "\n",
        "        # ACCdoc: with-doc correctness\n",
        "        out[\"accuracy_doc\"] = float(df[\"correct\"].mean())\n",
        "\n",
        "        # ED/CR conditioned on counterfactual examples\n",
        "        if \"is_counterfactual\" in df.columns and df[\"is_counterfactual\"].notna().any():\n",
        "            cf_mask = df[\"is_counterfactual\"] == 1\n",
        "        else:\n",
        "            cf_mask = pd.Series([True] * len(df), index=df.index)\n",
        "\n",
        "        if cf_mask.any():\n",
        "            ed = float(df.loc[cf_mask, \"is_error_detected\"].mean())\n",
        "            cr = float(((df.loc[cf_mask, \"is_error_detected\"] == 1) & (df.loc[cf_mask, \"correct\"] == 1)).mean())\n",
        "        else:\n",
        "            ed, cr = float(\"nan\"), float(\"nan\")\n",
        "\n",
        "        out[\"error_detection_rate\"] = ed\n",
        "        out[\"error_correction_rate\"] = cr\n",
        "        return out\n",
        "\n",
        "    return {}\n",
        "\n",
        "\n",
        "def run_split(\n",
        "    task: str,\n",
        "    split_path: str,\n",
        "    gen: HFGenerator,\n",
        "    out_dir: str,\n",
        "    passage_num: int,\n",
        "    noise_rate: float,\n",
        "    temperature: float,\n",
        "    top_p: float,\n",
        "    max_new_tokens: int,\n",
        "    seed: int,\n",
        ") -> pd.DataFrame:\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "    rng = random.Random(seed)\n",
        "    examples = infer_and_parse_examples(split_path)\n",
        "\n",
        "    rows: List[Dict[str, Any]] = []\n",
        "    out_jsonl = os.path.join(out_dir, \"generations.jsonl\")\n",
        "\n",
        "    with open(out_jsonl, \"w\", encoding=\"utf-8\") as f:\n",
        "        for ex in tqdm(examples, desc=f\"{task}:{os.path.basename(split_path)}:{noise_rate}\"):\n",
        "            # For counterfactual: compute ACC (no-doc) by an extra generation pass\n",
        "            gen_nodoc = None\n",
        "            correct_nodoc = None\n",
        "            if task == \"counterfactual\":\n",
        "                nodoc_prompt = build_prompt(ex.question, [])\n",
        "                gen_nodoc = gen.generate(\n",
        "                    SYSTEM_INSTRUCTION_EN,\n",
        "                    nodoc_prompt,\n",
        "                    max_new_tokens=max_new_tokens,\n",
        "                    temperature=temperature,\n",
        "                    top_p=top_p,\n",
        "                    seed=seed,\n",
        "                )\n",
        "                correct_nodoc = int(contains_any_answer(gen_nodoc, ex.answers))\n",
        "\n",
        "            docs = sample_docs(ex, passage_num=passage_num, noise_rate=noise_rate, rng=rng)\n",
        "            prompt = build_prompt(ex.question, docs)\n",
        "\n",
        "            text = gen.generate(\n",
        "                SYSTEM_INSTRUCTION_EN,\n",
        "                prompt,\n",
        "                max_new_tokens=max_new_tokens,\n",
        "                temperature=temperature,\n",
        "                top_p=top_p,\n",
        "                seed=seed,\n",
        "            )\n",
        "\n",
        "            correct = int(contains_any_answer(text, ex.answers))\n",
        "            rec = {\n",
        "                \"id\": ex.qid,\n",
        "                \"question\": ex.question,\n",
        "                \"answers\": ex.answers,\n",
        "                \"noise_rate\": noise_rate,\n",
        "                \"need_reject\": ex.need_reject,\n",
        "                \"is_counterfactual\": ex.is_counterfactual,\n",
        "                \"generation\": text,\n",
        "                \"correct\": correct,\n",
        "                \"is_rejection\": int(is_rejection(text)),\n",
        "                \"is_error_detected\": int(is_error_detected(text)),\n",
        "            }\n",
        "\n",
        "            if gen_nodoc is not None:\n",
        "                rec[\"generation_nodoc\"] = gen_nodoc\n",
        "                rec[\"correct_nodoc\"] = correct_nodoc\n",
        "\n",
        "            rows.append(rec)\n",
        "            f.write(json.dumps(rec, ensure_ascii=False) + \"\\n\")\n",
        "\n",
        "    df = pd.DataFrame(rows)\n",
        "    df.to_csv(os.path.join(out_dir, \"per_example.csv\"), index=False)\n",
        "    return df\n",
        "\n",
        "\n",
        "def main():\n",
        "    ap = argparse.ArgumentParser()\n",
        "    ap.add_argument(\"--data_dir\", required=True)\n",
        "    ap.add_argument(\"--out_dir\", required=True)\n",
        "    ap.add_argument(\"--model\", required=True)\n",
        "\n",
        "    ap.add_argument(\"--passage_num\", type=int, default=5)\n",
        "    ap.add_argument(\"--temperature\", type=float, default=0.2)\n",
        "    ap.add_argument(\"--top_p\", type=float, default=0.95)\n",
        "    ap.add_argument(\"--max_new_tokens\", type=int, default=256)\n",
        "    ap.add_argument(\"--seed\", type=int, default=42)\n",
        "\n",
        "    args = ap.parse_args()\n",
        "\n",
        "    suite = [\n",
        "        (\"noise\", \"en_refine.json\", [0.0, 0.2, 0.4, 0.6, 0.8]),\n",
        "        (\"rejection\", \"en_refine.json\", [1.0]),\n",
        "        (\"integration\", \"en_int.json\", [0.0]),\n",
        "        (\"counterfactual\", \"en_fact.json\", [0.0]),\n",
        "    ]\n",
        "\n",
        "    gen = HFGenerator(args.model)\n",
        "\n",
        "    summary_rows: List[Dict[str, Any]] = []\n",
        "    for task, fname, noise_rates in suite:\n",
        "        split_path = os.path.join(args.data_dir, fname)\n",
        "        if not os.path.exists(split_path):\n",
        "            print(f\"[WARN] missing {split_path}, skipping.\")\n",
        "            continue\n",
        "\n",
        "        for nr in noise_rates:\n",
        "            run_dir = os.path.join(\n",
        "                args.out_dir,\n",
        "                args.model.replace(\"/\", \"__\"),\n",
        "                f\"{task}_{fname.replace('.json', '')}\",\n",
        "                f\"noise_{nr}\",\n",
        "            )\n",
        "\n",
        "            df = run_split(\n",
        "                task=task,\n",
        "                split_path=split_path,\n",
        "                gen=gen,\n",
        "                out_dir=run_dir,\n",
        "                passage_num=args.passage_num,\n",
        "                noise_rate=nr,\n",
        "                temperature=args.temperature,\n",
        "                top_p=args.top_p,\n",
        "                max_new_tokens=args.max_new_tokens,\n",
        "                seed=args.seed,\n",
        "            )\n",
        "            met = summarize(df, task)\n",
        "            summary_rows.append(\n",
        "                {\n",
        "                    \"model\": args.model,\n",
        "                    \"task\": task,\n",
        "                    \"file\": fname,\n",
        "                    \"noise_rate\": nr,\n",
        "                    \"n\": len(df),\n",
        "                    **met,\n",
        "                }\n",
        "            )\n",
        "\n",
        "    summary_df = pd.DataFrame(summary_rows)\n",
        "    os.makedirs(args.out_dir, exist_ok=True)\n",
        "    summary_df.to_csv(os.path.join(args.out_dir, \"summary.csv\"), index=False)\n",
        "    print(summary_df)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fw3uu4g4NtK0",
        "outputId": "70c98cd8-bf61-4962-c187-b6e79d5844fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing rgb_eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content -name rgb_eval.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyxYoDfaB2Sn",
        "outputId": "6d92b371-1ffa-436b-8f20-4c4e15fea647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rgb_eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/rgb_eval.py --data_dir RGB/data --out_dir /content/runs_rgb --model Qwen/Qwen2.5-7B-Instruct"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzI8Tz-ZCDJI",
        "outputId": "34257465-1324-4990-810f-fe51c98d776e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 7.30kB [00:00, 3.87MB/s]\n",
            "vocab.json: 2.78MB [00:00, 35.9MB/s]\n",
            "merges.txt: 1.67MB [00:00, 58.2MB/s]\n",
            "tokenizer.json: 7.03MB [00:00, 29.4MB/s]\n",
            "config.json: 100% 663/663 [00:00<00:00, 6.19MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-18 13:25:40.840920: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-18 13:25:40.860720: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768742740.880049    4318 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768742740.885422    4318 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768742740.900096    4318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768742740.900131    4318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768742740.900136    4318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768742740.900140    4318 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-18 13:25:40.905000: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors.index.json: 27.8kB [00:00, 94.9MB/s]\n",
            "Fetching 4 files:   0% 0/4 [00:00<?, ?it/s]\n",
            "model-00001-of-00004.safetensors:   0% 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 0.00/3.56G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 17.3k/3.56G [00:01<111:32:48, 8.86kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 1.37M/3.86G [00:02<1:34:30, 681kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:   0% 7.15M/3.86G [00:02<18:16, 3.52MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   0% 8.53M/3.86G [00:02<11:59, 5.36MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:   3% 100M/3.86G [00:02<01:00, 61.9MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 41.3k/3.56G [00:02<50:04:59, 19.7kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:   6% 222M/3.86G [00:02<00:28, 130MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 58.8k/3.56G [00:02<33:46:23, 29.3kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   2% 89.9M/3.86G [00:02<01:09, 54.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:   7% 275M/3.86G [00:02<00:22, 160MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 24.8k/3.95G [00:02<119:29:03, 9.17kB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:   9% 348M/3.86G [00:02<00:14, 246MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 86.1k/3.56G [00:02<21:39:07, 45.6kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  11% 409M/3.86G [00:02<00:13, 262MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 666k/3.95G [00:02<3:31:24, 311kB/s]    \u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  14% 545M/3.86G [00:02<00:08, 413MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 849k/3.56G [00:02<1:16:48, 772kB/s]   \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  15% 561M/3.86G [00:03<00:10, 329MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  17% 673M/3.86G [00:03<00:07, 407MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 7.58M/3.95G [00:03<16:19, 4.02MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  18% 695M/3.86G [00:03<00:07, 415MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   0% 1.03M/3.56G [00:03<1:29:03, 665kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  21% 807M/3.86G [00:03<00:06, 487MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   2% 71.9M/3.56G [00:03<00:44, 79.2MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 8.58M/3.95G [00:03<16:17, 4.03MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  21% 829M/3.86G [00:03<00:06, 458MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 9.40M/3.95G [00:03<15:12, 4.31MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   4% 139M/3.56G [00:03<00:25, 132MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  23% 900M/3.86G [00:03<00:07, 403MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 10.7M/3.95G [00:03<13:20, 4.91MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  23% 897M/3.86G [00:04<00:11, 255MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  25% 971M/3.86G [00:04<00:10, 275MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   6% 207M/3.56G [00:04<00:27, 123MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 12.1M/3.95G [00:04<17:00, 3.85MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  25% 964M/3.86G [00:04<00:11, 253MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  26% 1.02G/3.86G [00:06<00:29, 95.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  28% 1.06G/3.86G [00:06<00:26, 108MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  29% 1.13G/3.86G [00:06<00:19, 143MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 13.5M/3.95G [00:06<44:27, 1.47MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  31% 1.20G/3.86G [00:06<00:16, 158MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  33% 1.26G/3.86G [00:06<00:14, 180MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  33% 1.28G/3.86G [00:06<00:12, 209MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  35% 1.36G/3.86G [00:07<00:11, 223MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   7% 240M/3.56G [00:07<01:30, 36.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 14.7M/3.95G [00:07<40:25, 1.62MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  37% 1.42G/3.86G [00:07<00:10, 230MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 15.3M/3.95G [00:07<37:58, 1.72MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  43% 1.68G/3.86G [00:07<00:05, 372MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 16.9M/3.95G [00:07<26:55, 2.43MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:   9% 313M/3.56G [00:07<00:59, 54.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  10% 346M/3.56G [00:07<00:50, 63.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   0% 19.1M/3.95G [00:07<18:55, 3.46MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  37% 1.43G/3.86G [00:08<00:15, 154MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 20.8M/3.95G [00:08<17:43, 3.69MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  12% 413M/3.56G [00:08<00:41, 76.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  47% 1.80G/3.86G [00:08<00:07, 269MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 25.0M/3.95G [00:10<22:47, 2.87MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  39% 1.50G/3.86G [00:10<00:36, 65.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  14% 480M/3.56G [00:10<01:03, 48.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  49% 1.89G/3.86G [00:10<00:16, 122MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  44% 1.69G/3.86G [00:11<00:17, 125MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  52% 2.03G/3.86G [00:11<00:11, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  46% 1.76G/3.86G [00:11<00:14, 148MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 25.6M/3.95G [00:11<31:57, 2.04MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  48% 1.87G/3.86G [00:11<00:09, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  51% 1.97G/3.86G [00:11<00:07, 259MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 27.0M/3.95G [00:11<26:10, 2.49MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  54% 2.09G/3.86G [00:11<00:10, 164MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  15% 547M/3.56G [00:11<00:49, 60.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  16% 586M/3.56G [00:11<00:41, 72.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   1% 58.4M/3.95G [00:11<03:40, 17.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  17% 620M/3.56G [00:11<00:36, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  53% 2.05G/3.86G [00:11<00:08, 215MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   3% 126M/3.95G [00:12<01:07, 56.2MB/s] \u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  56% 2.15G/3.86G [00:12<00:12, 138MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   5% 193M/3.95G [00:12<00:40, 92.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  20% 716M/3.56G [00:12<00:26, 107MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  55% 2.11G/3.86G [00:12<00:10, 160MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  22% 783M/3.56G [00:14<00:41, 66.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  56% 2.18G/3.86G [00:14<00:22, 75.7MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  24% 850M/3.56G [00:14<00:37, 71.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  64% 2.46G/3.86G [00:15<00:07, 178MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  57% 2.22G/3.86G [00:15<00:26, 62.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  31% 1.12G/3.56G [00:15<00:13, 176MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   7% 261M/3.95G [00:15<01:32, 39.8MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  58% 2.25G/3.86G [00:15<00:23, 69.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  67% 2.59G/3.86G [00:15<00:06, 204MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  60% 2.32G/3.86G [00:15<00:18, 84.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  33% 1.19G/3.56G [00:15<00:15, 152MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  69% 2.66G/3.86G [00:16<00:06, 188MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  62% 2.38G/3.86G [00:16<00:15, 98.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  35% 1.25G/3.56G [00:16<00:14, 161MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  71% 2.76G/3.86G [00:16<00:05, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  63% 2.45G/3.86G [00:16<00:14, 99.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  36% 1.30G/3.56G [00:16<00:16, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:   8% 312M/3.95G [00:18<02:23, 25.2MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  65% 2.51G/3.86G [00:19<00:23, 58.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  73% 2.84G/3.86G [00:19<00:11, 86.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  38% 1.37G/3.56G [00:19<00:30, 71.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  71% 2.73G/3.86G [00:19<00:08, 127MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  43% 1.53G/3.56G [00:19<00:15, 128MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  45% 1.60G/3.56G [00:19<00:12, 155MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  47% 1.67G/3.56G [00:19<00:10, 187MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  72% 2.80G/3.86G [00:19<00:07, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  74% 2.86G/3.86G [00:19<00:12, 77.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  54% 1.91G/3.56G [00:20<00:06, 265MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  75% 2.90G/3.86G [00:20<00:11, 80.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  76% 2.95G/3.86G [00:20<00:09, 99.6MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  74% 2.87G/3.86G [00:20<00:08, 120MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  55% 1.97G/3.56G [00:20<00:06, 245MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  75% 2.90G/3.86G [00:20<00:07, 121MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  78% 3.03G/3.86G [00:20<00:07, 104MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  57% 2.03G/3.56G [00:21<00:08, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  79% 3.07G/3.86G [00:23<00:15, 52.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  77% 2.97G/3.86G [00:23<00:14, 62.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 383M/3.95G [00:23<02:46, 21.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  60% 2.12G/3.56G [00:23<00:14, 99.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  80% 3.10G/3.86G [00:23<00:07, 106MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  64% 2.26G/3.56G [00:23<00:08, 150MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  83% 3.19G/3.86G [00:23<00:04, 143MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 390M/3.95G [00:23<02:44, 21.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  82% 3.19G/3.86G [00:23<00:07, 89.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  65% 2.31G/3.56G [00:23<00:07, 170MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  67% 2.37G/3.56G [00:23<00:05, 203MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  86% 3.32G/3.86G [00:23<00:03, 146MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  68% 2.43G/3.56G [00:23<00:05, 206MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  10% 395M/3.95G [00:23<02:52, 20.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  88% 3.42G/3.86G [00:24<00:03, 133MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  84% 3.26G/3.86G [00:24<00:05, 111MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  72% 2.57G/3.56G [00:24<00:05, 196MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  73% 2.61G/3.56G [00:24<00:04, 205MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 465M/3.95G [00:24<01:47, 32.5MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  86% 3.33G/3.86G [00:25<00:05, 107MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 476M/3.95G [00:25<01:47, 32.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  75% 2.68G/3.56G [00:25<00:04, 180MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  76% 2.71G/3.56G [00:25<00:04, 175MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  90% 3.49G/3.86G [00:25<00:03, 110MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 481M/3.95G [00:25<02:03, 28.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  91% 3.53G/3.86G [00:25<00:02, 118MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  88% 3.40G/3.86G [00:25<00:04, 110MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  77% 2.74G/3.56G [00:25<00:05, 160MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  93% 3.60G/3.86G [00:26<00:02, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 484M/3.95G [00:26<02:33, 22.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  79% 2.81G/3.56G [00:26<00:05, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  12% 489M/3.95G [00:26<02:29, 23.2MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 500M/3.95G [00:26<02:05, 27.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 504M/3.95G [00:26<02:04, 27.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  95% 3.66G/3.86G [00:26<00:01, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 509M/3.95G [00:26<01:53, 30.3MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 516M/3.95G [00:27<01:47, 31.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  81% 2.89G/3.56G [00:27<00:06, 106MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors:  97% 3.73G/3.86G [00:27<00:01, 115MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 520M/3.95G [00:27<02:31, 22.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  82% 2.92G/3.56G [00:27<00:05, 118MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  13% 529M/3.95G [00:27<01:54, 29.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00003-of-00004.safetensors: 100% 3.86G/3.86G [00:27<00:00, 139MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  84% 2.99G/3.56G [00:27<00:03, 142MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 535M/3.95G [00:27<01:53, 30.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  87% 3.08G/3.56G [00:27<00:02, 209MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 543M/3.95G [00:27<01:32, 36.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 548M/3.95G [00:28<01:41, 33.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  89% 3.15G/3.56G [00:28<00:01, 223MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  92% 3.29G/3.56G [00:28<00:00, 334MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 566M/3.95G [00:28<01:15, 44.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  94% 3.36G/3.56G [00:28<00:00, 214MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  14% 571M/3.95G [00:28<02:16, 24.8MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  16% 649M/3.95G [00:29<00:53, 61.5MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  19% 732M/3.95G [00:29<00:26, 123MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  96% 3.42G/3.56G [00:29<00:00, 137MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  20% 773M/3.95G [00:30<00:23, 137MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  90% 3.46G/3.86G [00:30<00:10, 39.9MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  23% 905M/3.95G [00:30<00:11, 275MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  24% 964M/3.95G [00:30<00:11, 269MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  91% 3.53G/3.86G [00:30<00:06, 51.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  27% 1.08G/3.95G [00:30<00:08, 321MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  93% 3.60G/3.86G [00:30<00:04, 67.1MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  30% 1.18G/3.95G [00:30<00:07, 376MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  95% 3.66G/3.86G [00:31<00:02, 83.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors:  98% 3.49G/3.56G [00:31<00:00, 81.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  32% 1.28G/3.95G [00:32<00:16, 161MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors:  97% 3.73G/3.86G [00:32<00:01, 67.6MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00004.safetensors:  34% 1.34G/3.95G [00:33<00:22, 113MB/s]\u001b[A\n",
            "\n",
            "model-00002-of-00004.safetensors: 100% 3.86G/3.86G [00:33<00:00, 116MB/s] \n",
            "\n",
            "model-00001-of-00004.safetensors:  37% 1.46G/3.95G [00:33<00:14, 169MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "model-00004-of-00004.safetensors: 100% 3.56G/3.56G [00:33<00:00, 106MB/s] \n",
            "\n",
            "model-00001-of-00004.safetensors:  42% 1.68G/3.95G [00:33<00:08, 274MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  49% 1.95G/3.95G [00:33<00:04, 455MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  53% 2.09G/3.95G [00:34<00:04, 429MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  56% 2.23G/3.95G [00:34<00:04, 412MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  59% 2.34G/3.95G [00:34<00:03, 403MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  61% 2.41G/3.95G [00:35<00:03, 396MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  63% 2.50G/3.95G [00:35<00:03, 367MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  66% 2.62G/3.95G [00:35<00:04, 313MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  67% 2.66G/3.95G [00:36<00:04, 286MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  69% 2.73G/3.95G [00:36<00:05, 237MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  71% 2.80G/3.95G [00:37<00:05, 202MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  73% 2.86G/3.95G [00:37<00:05, 205MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  77% 3.02G/3.95G [00:37<00:02, 343MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  81% 3.18G/3.95G [00:37<00:01, 497MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  86% 3.38G/3.95G [00:37<00:00, 613MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  89% 3.52G/3.95G [00:38<00:00, 581MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  92% 3.62G/3.95G [00:38<00:00, 545MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  93% 3.68G/3.95G [00:38<00:00, 509MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  95% 3.75G/3.95G [00:38<00:00, 477MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors:  97% 3.82G/3.95G [00:38<00:00, 453MB/s]\u001b[A\n",
            "model-00001-of-00004.safetensors: 100% 3.95G/3.95G [00:39<00:00, 101MB/s]\n",
            "Fetching 4 files: 100% 4/4 [00:39<00:00,  9.92s/it]\n",
            "Loading checkpoint shards: 100% 4/4 [00:04<00:00,  1.08s/it]\n",
            "generation_config.json: 100% 243/243 [00:00<00:00, 1.22MB/s]\n",
            "noise:en_refine.json:0.0: 100% 300/300 [05:24<00:00,  1.08s/it]\n",
            "noise:en_refine.json:0.2: 100% 300/300 [05:27<00:00,  1.09s/it]\n",
            "noise:en_refine.json:0.4: 100% 300/300 [06:06<00:00,  1.22s/it]\n",
            "noise:en_refine.json:0.6: 100% 300/300 [06:29<00:00,  1.30s/it]\n",
            "noise:en_refine.json:0.8: 100% 300/300 [08:11<00:00,  1.64s/it]\n",
            "rejection:en_refine.json:1.0: 100% 300/300 [09:28<00:00,  1.89s/it]\n",
            "integration:en_int.json:0.0: 100% 100/100 [00:54<00:00,  1.84it/s]\n",
            "counterfactual:en_fact.json:0.0: 100% 100/100 [03:02<00:00,  1.83s/it]\n",
            "                      model  ... error_correction_rate\n",
            "0  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "1  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "2  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "3  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "4  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "5  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "6  Qwen/Qwen2.5-7B-Instruct  ...                   NaN\n",
            "7  Qwen/Qwen2.5-7B-Instruct  ...                   0.0\n",
            "\n",
            "[8 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python rgb_eval.py --data_dir RGB/data --out_dir \"./runs_rgb\" --model mistralai/Mistral-7B-Instruct-v0.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZ9LMKrZeQYX",
        "outputId": "01dca55b-891c-4e5a-a39d-ef58ec3e2bb2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 141kB [00:00, 205MB/s]\n",
            "tokenizer.model: 100% 587k/587k [00:01<00:00, 450kB/s]\n",
            "tokenizer.json: 1.96MB [00:00, 199MB/s]\n",
            "special_tokens_map.json: 100% 414/414 [00:00<00:00, 385kB/s]\n",
            "config.json: 100% 601/601 [00:00<00:00, 4.36MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-18 14:20:10.480344: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-18 14:20:10.496508: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768746010.516242   18260 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768746010.523041   18260 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768746010.539663   18260 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768746010.539702   18260 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768746010.539706   18260 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768746010.539708   18260 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-18 14:20:10.544781: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors.index.json: 23.9kB [00:00, 88.6MB/s]\n",
            "Fetching 3 files:   0% 0/3 [00:00<?, ?it/s]\n",
            "model-00001-of-00003.safetensors:   0% 0.00/4.95G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   0% 0.00/4.55G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 0.00/5.00G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:   1% 67.0M/4.95G [00:01<02:24, 33.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   0% 1.10M/5.00G [00:02<2:39:24, 523kB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  18% 872M/4.95G [00:02<00:07, 531MB/s]  \u001b[A\n",
            "model-00001-of-00003.safetensors:  23% 1.15G/4.95G [00:02<00:07, 529MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   1% 68.2M/5.00G [00:02<02:51, 28.7MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  27% 1.34G/4.95G [00:03<00:06, 539MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   1% 61.7M/4.55G [00:03<03:43, 20.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   4% 202M/5.00G [00:03<00:47, 102MB/s]  \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   5% 269M/5.00G [00:03<00:37, 126MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  30% 1.48G/4.95G [00:03<00:08, 423MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   3% 129M/4.55G [00:03<01:54, 38.7MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   8% 403M/5.00G [00:04<00:28, 161MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:   9% 470M/5.00G [00:06<01:00, 74.9MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  33% 1.61G/4.95G [00:06<00:20, 166MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   4% 196M/4.55G [00:06<02:15, 32.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  12% 605M/5.00G [00:06<00:35, 125MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  35% 1.75G/4.95G [00:06<00:15, 205MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   7% 330M/4.55G [00:06<00:59, 71.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  13% 672M/5.00G [00:06<00:28, 153MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  37% 1.81G/4.95G [00:06<00:13, 224MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  15% 739M/5.00G [00:06<00:25, 169MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  38% 1.88G/4.95G [00:06<00:13, 225MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:   9% 397M/4.55G [00:07<00:52, 78.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  17% 873M/5.00G [00:07<00:18, 219MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  39% 1.95G/4.95G [00:07<00:15, 198MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  10% 464M/4.55G [00:07<00:44, 91.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  19% 940M/5.00G [00:07<00:22, 184MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  41% 2.01G/4.95G [00:07<00:16, 178MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  20% 1.01G/5.00G [00:08<00:21, 187MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  12% 531M/4.55G [00:08<00:43, 91.4MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  42% 2.08G/4.95G [00:10<00:37, 76.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  22% 1.08G/5.00G [00:10<00:50, 77.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  13% 598M/4.55G [00:10<01:07, 58.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  18% 799M/4.55G [00:10<00:29, 125MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  21% 934M/4.55G [00:10<00:20, 179MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  45% 2.22G/4.95G [00:11<00:26, 103MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  24% 1.21G/5.00G [00:11<00:36, 103MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  23% 1.06G/4.55G [00:11<00:18, 185MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  48% 2.35G/4.95G [00:11<00:19, 133MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  26% 1.20G/4.55G [00:11<00:13, 246MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  27% 1.34G/5.00G [00:11<00:30, 121MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  49% 2.42G/4.95G [00:12<00:20, 126MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  28% 1.27G/4.55G [00:12<00:16, 196MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  50% 2.49G/4.95G [00:12<00:16, 154MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  28% 1.41G/5.00G [00:12<00:34, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  52% 2.55G/4.95G [00:12<00:16, 144MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  30% 1.34G/4.55G [00:13<00:23, 139MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  31% 1.54G/5.00G [00:13<00:24, 139MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  53% 2.62G/4.95G [00:13<00:16, 145MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  31% 1.41G/4.55G [00:13<00:23, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  32% 1.61G/5.00G [00:13<00:25, 135MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  54% 2.68G/4.95G [00:13<00:16, 137MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  34% 1.54G/4.55G [00:14<00:17, 172MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  34% 1.68G/5.00G [00:14<00:25, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  56% 2.75G/4.95G [00:14<00:17, 123MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  35% 1.61G/4.55G [00:14<00:17, 166MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  35% 1.74G/5.00G [00:14<00:25, 125MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  57% 2.82G/4.95G [00:15<00:17, 120MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  37% 1.68G/4.55G [00:15<00:18, 159MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  36% 1.81G/5.00G [00:15<00:24, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  58% 2.89G/4.95G [00:15<00:16, 127MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  38% 1.75G/4.55G [00:15<00:18, 149MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  38% 1.88G/5.00G [00:16<00:26, 119MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  60% 2.95G/4.95G [00:16<00:16, 123MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  40% 1.81G/4.55G [00:16<00:19, 143MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  41% 1.88G/4.55G [00:16<00:19, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  39% 1.95G/5.00G [00:17<00:29, 103MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  61% 3.02G/4.95G [00:17<00:20, 92.7MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  43% 1.95G/4.55G [00:17<00:20, 125MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  40% 2.01G/5.00G [00:17<00:26, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  62% 3.09G/4.95G [00:17<00:17, 106MB/s] \u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  44% 2.01G/4.55G [00:17<00:18, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  42% 2.08G/5.00G [00:18<00:25, 114MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  64% 3.15G/4.95G [00:18<00:15, 112MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  44% 2.21G/5.00G [00:18<00:18, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  66% 3.29G/4.95G [00:18<00:11, 149MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  46% 2.08G/4.55G [00:19<00:26, 94.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  46% 2.28G/5.00G [00:19<00:19, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  49% 2.21G/4.55G [00:19<00:17, 135MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  68% 3.36G/4.95G [00:19<00:13, 121MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  47% 2.35G/5.00G [00:19<00:18, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  50% 2.28G/4.55G [00:19<00:16, 136MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  48% 2.42G/5.00G [00:20<00:19, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  69% 3.43G/4.95G [00:20<00:13, 112MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  52% 2.35G/4.55G [00:20<00:17, 123MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  50% 2.49G/5.00G [00:20<00:20, 122MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  71% 3.49G/4.95G [00:21<00:13, 109MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  55% 2.48G/4.55G [00:21<00:13, 156MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  51% 2.55G/5.00G [00:21<00:18, 136MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  56% 2.55G/4.55G [00:21<00:13, 145MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  72% 3.56G/4.95G [00:21<00:14, 95.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  58% 2.62G/4.55G [00:22<00:12, 151MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  52% 2.62G/5.00G [00:22<00:23, 99.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  73% 3.63G/4.95G [00:22<00:13, 98.8MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  61% 2.75G/4.55G [00:22<00:10, 170MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  75% 3.69G/4.95G [00:22<00:11, 113MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  54% 2.69G/5.00G [00:22<00:22, 102MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  55% 2.75G/5.00G [00:23<00:18, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  76% 3.76G/4.95G [00:23<00:10, 114MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  62% 2.81G/4.55G [00:23<00:12, 142MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  56% 2.82G/5.00G [00:23<00:16, 129MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  77% 3.83G/4.95G [00:24<00:09, 116MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  65% 2.97G/4.55G [00:24<00:10, 158MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  79% 3.90G/4.95G [00:24<00:09, 116MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  58% 2.89G/5.00G [00:24<00:20, 102MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  67% 3.03G/4.55G [00:24<00:09, 165MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  59% 2.96G/5.00G [00:24<00:15, 128MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  68% 3.10G/4.55G [00:25<00:08, 164MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  80% 3.96G/4.95G [00:25<00:08, 117MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  60% 3.02G/5.00G [00:25<00:17, 111MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  81% 4.03G/4.95G [00:25<00:08, 115MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  70% 3.17G/4.55G [00:25<00:09, 138MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  62% 3.09G/5.00G [00:26<00:15, 124MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  71% 3.24G/4.55G [00:26<00:08, 156MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  83% 4.10G/4.95G [00:26<00:07, 113MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  73% 3.31G/4.55G [00:26<00:07, 162MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  63% 3.16G/5.00G [00:26<00:16, 113MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  84% 4.16G/4.95G [00:27<00:06, 116MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  74% 3.37G/4.55G [00:27<00:08, 144MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  85% 4.23G/4.95G [00:27<00:06, 119MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  64% 3.22G/5.00G [00:27<00:16, 105MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  76% 3.45G/4.55G [00:27<00:07, 152MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  66% 3.29G/5.00G [00:27<00:13, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  77% 3.52G/4.55G [00:27<00:06, 155MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  87% 4.30G/4.95G [00:28<00:05, 116MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  78% 3.56G/4.55G [00:28<00:06, 157MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  67% 3.36G/5.00G [00:28<00:13, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  88% 4.37G/4.95G [00:28<00:04, 117MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  80% 3.63G/4.55G [00:28<00:06, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  69% 3.43G/5.00G [00:30<00:26, 58.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  81% 3.69G/4.55G [00:30<00:12, 66.8MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  90% 4.43G/4.95G [00:30<00:08, 62.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  71% 3.56G/5.00G [00:31<00:13, 105MB/s] \u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  92% 4.57G/4.95G [00:31<00:03, 110MB/s] \u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  73% 3.63G/5.00G [00:31<00:10, 131MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  93% 4.61G/4.95G [00:31<00:02, 129MB/s]\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  84% 3.83G/4.55G [00:31<00:06, 113MB/s] \u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  96% 4.75G/4.95G [00:31<00:00, 209MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  74% 3.69G/5.00G [00:31<00:08, 152MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  86% 3.90G/4.55G [00:31<00:04, 133MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  88% 4.01G/4.55G [00:31<00:03, 171MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  90% 4.08G/4.55G [00:32<00:02, 180MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  97% 4.82G/4.95G [00:32<00:00, 152MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  75% 3.76G/5.00G [00:32<00:10, 123MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  91% 4.14G/4.55G [00:32<00:02, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  93% 4.21G/4.55G [00:32<00:01, 220MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  77% 3.83G/5.00G [00:32<00:09, 127MB/s]\u001b[A\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors:  99% 4.88G/4.95G [00:32<00:00, 129MB/s]\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  78% 3.89G/5.00G [00:33<00:07, 143MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  79% 3.96G/5.00G [00:33<00:07, 147MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  94% 4.28G/4.55G [00:33<00:01, 146MB/s]\u001b[A\u001b[A\n",
            "model-00001-of-00003.safetensors: 100% 4.95G/4.95G [00:33<00:00, 147MB/s]\n",
            "Fetching 3 files:  33% 1/3 [00:34<01:08, 34.04s/it]\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  81% 4.03G/5.00G [00:33<00:06, 149MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  96% 4.35G/4.55G [00:33<00:01, 146MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  97% 4.41G/4.55G [00:34<00:00, 161MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  82% 4.09G/5.00G [00:34<00:05, 159MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  83% 4.16G/5.00G [00:34<00:04, 183MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  85% 4.23G/5.00G [00:34<00:03, 220MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  86% 4.30G/5.00G [00:34<00:02, 242MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors:  99% 4.48G/4.55G [00:34<00:00, 134MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  87% 4.36G/5.00G [00:35<00:03, 193MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "model-00003-of-00003.safetensors: 100% 4.55G/4.55G [00:35<00:00, 128MB/s]\n",
            "\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.43G/5.00G [00:35<00:02, 211MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  89% 4.47G/5.00G [00:35<00:02, 231MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  91% 4.53G/5.00G [00:35<00:01, 262MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  92% 4.60G/5.00G [00:36<00:01, 286MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  93% 4.67G/5.00G [00:36<00:01, 306MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  95% 4.73G/5.00G [00:36<00:00, 322MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  96% 4.80G/5.00G [00:36<00:00, 331MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors:  97% 4.87G/5.00G [00:36<00:00, 340MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "model-00002-of-00003.safetensors: 100% 5.00G/5.00G [00:37<00:00, 135MB/s]\n",
            "Fetching 3 files: 100% 3/3 [00:37<00:00, 12.52s/it]\n",
            "Loading checkpoint shards: 100% 3/3 [00:04<00:00,  1.36s/it]\n",
            "generation_config.json: 100% 116/116 [00:00<00:00, 937kB/s]\n",
            "noise:en_refine.json:0.0: 100% 300/300 [06:57<00:00,  1.39s/it]\n",
            "noise:en_refine.json:0.2: 100% 300/300 [07:15<00:00,  1.45s/it]\n",
            "noise:en_refine.json:0.4: 100% 300/300 [07:55<00:00,  1.58s/it]\n",
            "noise:en_refine.json:0.6: 100% 300/300 [08:02<00:00,  1.61s/it]\n",
            "noise:en_refine.json:0.8: 100% 300/300 [10:22<00:00,  2.07s/it]\n",
            "rejection:en_refine.json:1.0: 100% 300/300 [13:57<00:00,  2.79s/it]\n",
            "integration:en_int.json:0.0: 100% 100/100 [05:02<00:00,  3.02s/it]\n",
            "counterfactual:en_fact.json:0.0: 100% 100/100 [06:53<00:00,  4.13s/it]\n",
            "                                model  ... error_correction_rate\n",
            "0  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "1  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "2  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "3  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "4  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "5  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "6  mistralai/Mistral-7B-Instruct-v0.3  ...                   NaN\n",
            "7  mistralai/Mistral-7B-Instruct-v0.3  ...                   0.0\n",
            "\n",
            "[8 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python rgb_eval.py --data_dir RGB/data --out_dir \"./runs_rgb\" --model microsoft/Phi-3.5-mini-instruct --max_new_tokens 128 --temperature 0.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EkdHbo5ouec4",
        "outputId": "7824b42f-c8fe-4095-f3f6-a3628927805d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokenizer_config.json: 3.98kB [00:00, 16.3MB/s]\n",
            "tokenizer.model: 100% 500k/500k [00:01<00:00, 416kB/s]\n",
            "tokenizer.json: 1.84MB [00:00, 51.3MB/s]\n",
            "added_tokens.json: 100% 306/306 [00:00<00:00, 2.73MB/s]\n",
            "special_tokens_map.json: 100% 665/665 [00:00<00:00, 4.45MB/s]\n",
            "config.json: 3.45kB [00:00, 17.8MB/s]\n",
            "`torch_dtype` is deprecated! Use `dtype` instead!\n",
            "2026-01-18 15:31:11.500489: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2026-01-18 15:31:11.518817: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1768750271.540442   36402 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1768750271.546995   36402 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1768750271.563361   36402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768750271.563387   36402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768750271.563391   36402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1768750271.563393   36402 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-01-18 15:31:11.568280: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "model.safetensors.index.json: 16.3kB [00:00, 59.2MB/s]\n",
            "Fetching 2 files:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/2.67G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 0.00/4.97G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:   1% 16.5M/2.67G [00:01<04:08, 10.7MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   9% 232M/2.67G [00:02<00:18, 131MB/s]  \u001b[A\n",
            "model-00002-of-00002.safetensors:  43% 1.15G/2.67G [00:02<00:01, 824MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   0% 2.10M/4.97G [00:02<1:47:08, 773kB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   4% 183M/4.97G [00:02<00:55, 86.2MB/s]  \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   6% 284M/4.97G [00:03<00:32, 143MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   7% 365M/4.97G [00:03<00:24, 191MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:   9% 432M/4.97G [00:03<00:20, 225MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  10% 499M/4.97G [00:03<00:21, 205MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 1.58G/2.67G [00:03<00:02, 471MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  12% 583M/4.97G [00:04<00:18, 233MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  13% 650M/4.97G [00:04<00:17, 243MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  70% 1.86G/2.67G [00:05<00:02, 350MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  15% 736M/4.97G [00:05<00:28, 147MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  17% 842M/4.97G [00:05<00:19, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  18% 909M/4.97G [00:05<00:17, 238MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  19% 954M/4.97G [00:07<00:52, 75.9MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 2.08G/2.67G [00:07<00:02, 204MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  23% 1.12G/4.97G [00:07<00:26, 146MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 2.22G/2.67G [00:08<00:01, 236MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  24% 1.21G/4.97G [00:08<00:21, 179MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 2.35G/2.67G [00:08<00:01, 270MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  26% 1.28G/4.97G [00:08<00:17, 210MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  27% 1.34G/4.97G [00:08<00:15, 241MB/s]\u001b[A\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 2.49G/2.67G [00:08<00:00, 305MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  97% 2.60G/2.67G [00:08<00:00, 300MB/s]\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  29% 1.45G/4.97G [00:08<00:14, 243MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  30% 1.51G/4.97G [00:09<00:13, 266MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  32% 1.59G/4.97G [00:09<00:11, 290MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  34% 1.67G/4.97G [00:09<00:10, 314MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  35% 1.74G/4.97G [00:09<00:09, 326MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  37% 1.82G/4.97G [00:09<00:09, 343MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  38% 1.88G/4.97G [00:11<00:33, 91.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  41% 2.03G/4.97G [00:12<00:18, 157MB/s] \u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  43% 2.15G/4.97G [00:12<00:12, 222MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  46% 2.27G/4.97G [00:12<00:09, 298MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00002-of-00002.safetensors: 100% 2.67G/2.67G [00:12<00:00, 211MB/s]\n",
            "\n",
            "\n",
            "model-00001-of-00002.safetensors:  51% 2.54G/4.97G [00:12<00:04, 521MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  54% 2.66G/4.97G [00:12<00:03, 635MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  56% 2.80G/4.97G [00:12<00:02, 758MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  59% 2.95G/4.97G [00:13<00:02, 694MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  62% 3.07G/4.97G [00:13<00:04, 392MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  65% 3.22G/4.97G [00:13<00:03, 473MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  68% 3.37G/4.97G [00:14<00:05, 304MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  69% 3.43G/4.97G [00:15<00:06, 223MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  70% 3.49G/4.97G [00:15<00:07, 198MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  71% 3.55G/4.97G [00:16<00:06, 208MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  77% 3.81G/4.97G [00:16<00:02, 416MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  79% 3.93G/4.97G [00:16<00:02, 496MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  82% 4.08G/4.97G [00:16<00:01, 588MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  85% 4.21G/4.97G [00:16<00:01, 650MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  88% 4.38G/4.97G [00:16<00:00, 760MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  91% 4.51G/4.97G [00:17<00:00, 610MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  93% 4.64G/4.97G [00:17<00:00, 503MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  96% 4.75G/4.97G [00:17<00:00, 472MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  97% 4.82G/4.97G [00:18<00:00, 455MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors:  98% 4.90G/4.97G [00:18<00:00, 419MB/s]\u001b[A\u001b[A\n",
            "\n",
            "model-00001-of-00002.safetensors: 100% 4.97G/4.97G [00:18<00:00, 270MB/s]\n",
            "Fetching 2 files: 100% 2/2 [00:18<00:00,  9.45s/it]\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.09s/it]\n",
            "generation_config.json: 100% 195/195 [00:00<00:00, 1.38MB/s]\n",
            "noise:en_refine.json:0.0: 100% 300/300 [11:14<00:00,  2.25s/it]\n",
            "noise:en_refine.json:0.2: 100% 300/300 [10:29<00:00,  2.10s/it]\n",
            "noise:en_refine.json:0.4: 100% 300/300 [09:52<00:00,  1.97s/it]\n",
            "noise:en_refine.json:0.6: 100% 300/300 [10:50<00:00,  2.17s/it]\n",
            "noise:en_refine.json:0.8: 100% 300/300 [10:46<00:00,  2.15s/it]\n",
            "rejection:en_refine.json:1.0: 100% 300/300 [17:08<00:00,  3.43s/it]\n",
            "integration:en_int.json:0.0: 100% 100/100 [04:58<00:00,  2.99s/it]\n",
            "counterfactual:en_fact.json:0.0: 100% 100/100 [12:32<00:00,  7.53s/it]\n",
            "                             model  ... error_correction_rate\n",
            "0  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "1  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "2  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "3  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "4  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "5  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "6  microsoft/Phi-3.5-mini-instruct  ...                   NaN\n",
            "7  microsoft/Phi-3.5-mini-instruct  ...                  0.01\n",
            "\n",
            "[8 rows x 11 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login, HfApi\n",
        "import os\n",
        "\n",
        "login()  # paste token when prompted\n",
        "\n",
        "repo_id = \"vbupadhyaya/rgb-rag-run2\"   # <-- change this\n",
        "local_folder = \"/content/runs_rgb\"\n",
        "\n",
        "api = HfApi()\n",
        "# Create repo if it doesn't exist (type=\"dataset\" recommended for results)\n",
        "api.create_repo(repo_id=repo_id, repo_type=\"dataset\", exist_ok=True)\n",
        "\n",
        "# Upload entire folder\n",
        "api.upload_folder(\n",
        "    repo_id=repo_id,\n",
        "    repo_type=\"dataset\",\n",
        "    folder_path=local_folder,\n",
        "    path_in_repo=\"runs_rgb\"\n",
        ")\n",
        "\n",
        "print(\"Uploaded to HF:\", repo_id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162,
          "referenced_widgets": [
            "c4fbe35c771c49499bbd569fe74f4bd5",
            "35929e75334143e69e3fe2927a9e2d23",
            "ffbf15ef3fdd40769142d74a08319cfd",
            "b23ca7b412b74430a4e9687939911e17",
            "9233957b288242bd88d682f35ecd1735",
            "a6df3b7da6794518a5ba5d9f5f5a5025",
            "7ee36db0812e40aebe4eb1e9a0d02d63",
            "050996cc365542bdba705a6f3f741989",
            "a8e30721e4104c57ac9cb8ecce3c2a22",
            "8d192a0985934ca1b712c12846f3a59b",
            "84bb27f77c934277b44ccbc28ee40a09",
            "7bfa53d590244b6b8ff99bf05d9142a3",
            "768e89ef1ecc492c890989f070286496",
            "5df5c526eb954fbeabd745fa66717e6e",
            "17a44bdfe5864fb9a9c9e8fd1f2d4139",
            "e6a67d357d574dacad942afb35552e1c",
            "958da3f0c9864c59bbe96a3f5cf1106c",
            "810dab486b4640a0a3896867cde8d724",
            "1ce6eb0841674774aa14463a61b67604",
            "16ca75437e6942b080777104e4d42b60"
          ]
        },
        "id": "vlyUzXiQFRLX",
        "outputId": "0b0cf0fe-c371-4cde-ee75-e4dda8971417"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4fbe35c771c49499bbd569fe74f4bd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded to HF: vbupadhyaya/rgb-rag-run2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "\n",
        "# ---- Update this path to wherever your runs are saved ----\n",
        "SUMMARY_CSV = \"/content/runs_rgb/summary.csv\"\n",
        "\n",
        "summary = pd.read_csv(SUMMARY_CSV)\n",
        "\n",
        "# Keep a consistent model order\n",
        "models = sorted(summary[\"model\"].dropna().unique().tolist())\n",
        "\n",
        "def fmt(df):\n",
        "    \"\"\"Format numbers as 2 decimals; show missing as --\"\"\"\n",
        "    return df.applymap(lambda x: \"--\" if pd.isna(x) else f\"{x:.2f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 1) Noise Robustness (Accuracy %, English)\n",
        "# ----------------------------\n",
        "noise_rates_noise = [0.0, 0.2, 0.4, 0.6, 0.8]\n",
        "noise_tbl = (\n",
        "    summary[summary[\"task\"].eq(\"noise\")]\n",
        "    .assign(acc_pct=lambda x: x[\"accuracy\"] * 100)\n",
        "    .pivot_table(index=\"model\", columns=\"noise_rate\", values=\"acc_pct\", aggfunc=\"mean\")\n",
        "    .reindex(index=models, columns=noise_rates_noise)\n",
        ")\n",
        "noise_tbl.index.name = \"Model\"\n",
        "noise_tbl.columns = [f\"{c:.1f}\" for c in noise_rates_noise]\n",
        "\n",
        "# ----------------------------\n",
        "# 2) Negative Rejection (Rejection Rate %, English)\n",
        "#   Paper wants Rej only (no Rej*)\n",
        "#   In our patched eval, \"rejection_rate\" is conditioned on need_reject==1\n",
        "# ----------------------------\n",
        "rej_tbl = (\n",
        "    summary[summary[\"task\"].eq(\"rejection\")]\n",
        "    .groupby(\"model\")[\"rejection_rate\"]\n",
        "    .mean()\n",
        "    .mul(100)\n",
        "    .reindex(models)\n",
        "    .to_frame(\"Rej\")\n",
        ")\n",
        "rej_tbl.index.name = \"Model\"\n",
        "\n",
        "# ----------------------------\n",
        "# 3) Information Integration (Accuracy %, English)\n",
        "#   Paper shows 0.0, 0.2, 0.4 columns, but HF en_int often only has 0.0\n",
        "# ----------------------------\n",
        "noise_rates_integ = [0.0, 0.2, 0.4]\n",
        "integ_tbl = (\n",
        "    summary[summary[\"task\"].eq(\"integration\")]\n",
        "    .assign(acc_pct=lambda x: x[\"accuracy\"] * 100)\n",
        "    .pivot_table(index=\"model\", columns=\"noise_rate\", values=\"acc_pct\", aggfunc=\"mean\")\n",
        "    .reindex(index=models, columns=noise_rates_integ)\n",
        ")\n",
        "integ_tbl.index.name = \"Model\"\n",
        "integ_tbl.columns = [f\"{c:.1f}\" for c in noise_rates_integ]\n",
        "\n",
        "# ----------------------------\n",
        "# 4) Counterfactual Robustness (%, English)\n",
        "#   Paper columns: ACC, ACCdoc, ED, CR\n",
        "#   Our summary includes:\n",
        "#     accuracy_nodoc -> ACC\n",
        "#     accuracy_doc   -> ACCdoc\n",
        "#     error_detection_rate -> ED\n",
        "#     error_correction_rate -> CR\n",
        "# ----------------------------\n",
        "cf = summary[summary[\"task\"].eq(\"counterfactual\")].copy()\n",
        "\n",
        "cf_tbl = pd.DataFrame(index=models, columns=[\"ACC\", \"ACCdoc\", \"ED\", \"CR\"], dtype=float)\n",
        "cf_tbl.index.name = \"Model\"\n",
        "\n",
        "if \"accuracy_nodoc\" in cf.columns:\n",
        "    cf_tbl[\"ACC\"] = cf.groupby(\"model\")[\"accuracy_nodoc\"].mean().reindex(models) * 100\n",
        "if \"accuracy_doc\" in cf.columns:\n",
        "    cf_tbl[\"ACCdoc\"] = cf.groupby(\"model\")[\"accuracy_doc\"].mean().reindex(models) * 100\n",
        "\n",
        "if \"error_detection_rate\" in cf.columns:\n",
        "    cf_tbl[\"ED\"] = cf.groupby(\"model\")[\"error_detection_rate\"].mean().reindex(models) * 100\n",
        "if \"error_correction_rate\" in cf.columns:\n",
        "    cf_tbl[\"CR\"] = cf.groupby(\"model\")[\"error_correction_rate\"].mean().reindex(models) * 100\n",
        "\n",
        "# ----------------------------\n",
        "# Print EXACT paper-style tables\n",
        "# ----------------------------\n",
        "print(\"\\nNoise Robustness (Accuracy %, English)\\n\")\n",
        "display(fmt(noise_tbl))\n",
        "\n",
        "print(\"\\nNegative Rejection (Rejection Rate %, English)\\n\")\n",
        "display(fmt(rej_tbl))\n",
        "\n",
        "print(\"\\nInformation Integration (Accuracy %, English)\\n\")\n",
        "display(fmt(integ_tbl))\n",
        "\n",
        "print(\"\\nCounterfactual Robustness (%, English)\\n\")\n",
        "display(fmt(cf_tbl))\n",
        "\n",
        "# ----------------------------\n",
        "# Side-by-side layout (like the PDF)\n",
        "# ----------------------------\n",
        "def card(df, title):\n",
        "    return f\"\"\"\n",
        "    <div style=\"flex:1; min-width:360px; padding:12px; border:1px solid #ddd; border-radius:10px;\">\n",
        "        <div style=\"font-weight:700; margin-bottom:8px;\">{title}</div>\n",
        "        {fmt(df).to_html(escape=False)}\n",
        "    </div>\n",
        "    \"\"\"\n",
        "\n",
        "display(HTML(f\"\"\"\n",
        "<div style=\"display:flex; gap:14px; flex-wrap:wrap;\">\n",
        "    {card(noise_tbl, \"Noise Robustness (Accuracy %, English)\")}\n",
        "    {card(rej_tbl, \"Negative Rejection (Rejection Rate %, English)\")}\n",
        "</div>\n",
        "<div style=\"display:flex; gap:14px; flex-wrap:wrap; margin-top:14px;\">\n",
        "    {card(integ_tbl, \"Information Integration (Accuracy %, English)\")}\n",
        "    {card(cf_tbl, \"Counterfactual Robustness (%, English)\")}\n",
        "</div>\n",
        "\"\"\"))\n"
      ],
      "metadata": {
        "id": "OzY3sR4KBzTa"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "994dcb23cb954171b1e1b38202b91de8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_44fe089231b745ea86346a63471fa859"
          }
        },
        "5b5ad4b5490045cba76d868d897411fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bab1faec9af74f39bca7e74ed441dbb9",
            "placeholder": "​",
            "style": "IPY_MODEL_22050508dd884aecbc21b7168ca9f428",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "105bc2eead9f4d9f890c011a0d7128cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_247df6876b154d1fa2f32fbd80961a3f",
            "placeholder": "​",
            "style": "IPY_MODEL_0182461a90f14207b62fc7fd013ddf13",
            "value": ""
          }
        },
        "ffe32e45e135464cbcaa857368cae659": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_b0a0a6e9782f4b4f842c43c31603851e",
            "style": "IPY_MODEL_cce1bf37baf348559beeb8a9f02c8050",
            "value": true
          }
        },
        "9a6a6d4aa1cf446286e5d3a464383574": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ac5bee6870b6414ab3767940b67edc44",
            "style": "IPY_MODEL_f4644f215d7043479f45aad032ba7517",
            "tooltip": ""
          }
        },
        "889fe31bd6834308b74e2df51ab75f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9f83c676a424002b152e664df216a97",
            "placeholder": "​",
            "style": "IPY_MODEL_0717889b10f24f25bcf4d712f20a1e95",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "44fe089231b745ea86346a63471fa859": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "bab1faec9af74f39bca7e74ed441dbb9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22050508dd884aecbc21b7168ca9f428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "247df6876b154d1fa2f32fbd80961a3f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0182461a90f14207b62fc7fd013ddf13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b0a0a6e9782f4b4f842c43c31603851e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cce1bf37baf348559beeb8a9f02c8050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac5bee6870b6414ab3767940b67edc44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4644f215d7043479f45aad032ba7517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "b9f83c676a424002b152e664df216a97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0717889b10f24f25bcf4d712f20a1e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7b9dd1528ba4cbe983b9cced52c1bfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a466f895720e4797b729c196b41bc4d6",
            "placeholder": "​",
            "style": "IPY_MODEL_06117d9f785945629c94505af21cbd05",
            "value": "Connecting..."
          }
        },
        "a466f895720e4797b729c196b41bc4d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06117d9f785945629c94505af21cbd05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4fbe35c771c49499bbd569fe74f4bd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_7ee36db0812e40aebe4eb1e9a0d02d63"
          }
        },
        "35929e75334143e69e3fe2927a9e2d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_050996cc365542bdba705a6f3f741989",
            "placeholder": "​",
            "style": "IPY_MODEL_a8e30721e4104c57ac9cb8ecce3c2a22",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "ffbf15ef3fdd40769142d74a08319cfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8d192a0985934ca1b712c12846f3a59b",
            "placeholder": "​",
            "style": "IPY_MODEL_84bb27f77c934277b44ccbc28ee40a09",
            "value": ""
          }
        },
        "b23ca7b412b74430a4e9687939911e17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_7bfa53d590244b6b8ff99bf05d9142a3",
            "style": "IPY_MODEL_768e89ef1ecc492c890989f070286496",
            "value": true
          }
        },
        "9233957b288242bd88d682f35ecd1735": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_5df5c526eb954fbeabd745fa66717e6e",
            "style": "IPY_MODEL_17a44bdfe5864fb9a9c9e8fd1f2d4139",
            "tooltip": ""
          }
        },
        "a6df3b7da6794518a5ba5d9f5f5a5025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e6a67d357d574dacad942afb35552e1c",
            "placeholder": "​",
            "style": "IPY_MODEL_958da3f0c9864c59bbe96a3f5cf1106c",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "7ee36db0812e40aebe4eb1e9a0d02d63": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "050996cc365542bdba705a6f3f741989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8e30721e4104c57ac9cb8ecce3c2a22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d192a0985934ca1b712c12846f3a59b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bb27f77c934277b44ccbc28ee40a09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bfa53d590244b6b8ff99bf05d9142a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "768e89ef1ecc492c890989f070286496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5df5c526eb954fbeabd745fa66717e6e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17a44bdfe5864fb9a9c9e8fd1f2d4139": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e6a67d357d574dacad942afb35552e1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "958da3f0c9864c59bbe96a3f5cf1106c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "810dab486b4640a0a3896867cde8d724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ce6eb0841674774aa14463a61b67604",
            "placeholder": "​",
            "style": "IPY_MODEL_16ca75437e6942b080777104e4d42b60",
            "value": "Connecting..."
          }
        },
        "1ce6eb0841674774aa14463a61b67604": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "16ca75437e6942b080777104e4d42b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}