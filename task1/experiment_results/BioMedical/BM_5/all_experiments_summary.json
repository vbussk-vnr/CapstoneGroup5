{
  "timestamp": "2026-01-24T01:44:43.488915",
  "total_experiments": 8,
  "experiments": [
    {
      "experiment": "legal_baseline_dense_minilm",
      "config": {
        "name": "legal_baseline_dense_minilm",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Baseline: Dense with general embeddings",
        "chunking_strategy": "sentence_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "dense",
        "top_k_final": 5,
        "use_cross_encoder": false,
        "hybrid_alpha": 0.0,
        "expected_improvement": "0%",
        "rationale": "Standard baseline"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.5795102532808121,
          "aucroc": null,
          "mean_predicted": 0.1106556389230241,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.0351642742196687,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.0728419972177076,
          "aucroc": null,
          "mean_predicted": 0.05025731940826851,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.022500707551381928,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.6123816929566728,
          "aucroc": null,
          "mean_predicted": 0.44190476190476186,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.2520734874672468,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.4,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.48989794855663565,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_baseline_sparse_bm25",
      "config": {
        "name": "legal_baseline_sparse_bm25",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Baseline: Sparse - captures legal terms",
        "chunking_strategy": "sentence_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "sparse",
        "top_k_final": 5,
        "use_cross_encoder": false,
        "hybrid_alpha": 0.0,
        "expected_improvement": "0%",
        "rationale": "BM25 good for legal terminology"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.6251725872516396,
          "aucroc": null,
          "mean_predicted": 0.0070082027514161704,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.009320677717428881,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.06423091403438919,
          "aucroc": null,
          "mean_predicted": 0.0070082027514161704,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.009320677717428881,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.7071067811865476,
          "aucroc": null,
          "mean_predicted": 0.4,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.48989794855663565,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.0,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.0,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp1_dense_legalbert",
      "config": {
        "name": "legal_exp1_dense_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Dense with LegalBERT (domain-specific)",
        "chunking_strategy": "sentence_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "dense",
        "top_k_final": 5,
        "use_cross_encoder": false,
        "hybrid_alpha": 0.0,
        "expected_improvement": "+20-30%",
        "rationale": "LegalBERT trained on legal documents"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.5740699779142415,
          "aucroc": null,
          "mean_predicted": 0.14871123756564705,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.06717705664336858,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.11274105301597767,
          "aucroc": null,
          "mean_predicted": 0.07729265149188856,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.056743999585146185,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.7065654208051446,
          "aucroc": null,
          "mean_predicted": 0.6357142857142857,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.38092261788495385,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.6,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.48989794855663565,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp2_hybrid_legalbert",
      "config": {
        "name": "legal_exp2_hybrid_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Hybrid with LegalBERT + Reranking",
        "chunking_strategy": "sentence_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "hybrid",
        "top_k_final": 5,
        "use_cross_encoder": true,
        "cross_encoder_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "hybrid_alpha": 0.5,
        "expected_improvement": "+35-45%",
        "rationale": "Legal + semantic + exact phrase matching"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.5095764757128931,
          "aucroc": null,
          "mean_predicted": 0.16475482703669816,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.11603284824815259,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.1475118933674998,
          "aucroc": null,
          "mean_predicted": 0.09994444839537,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.09951083821589796,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.5621565739809115,
          "aucroc": null,
          "mean_predicted": 0.6859477124183007,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.30422783079045884,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.2,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.4000000000000001,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp3_paragraph_chunking_legalbert",
      "config": {
        "name": "legal_exp3_paragraph_chunking_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Paragraph-based chunking (preserves clause structure)",
        "chunking_strategy": "paragraph_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "hybrid",
        "top_k_final": 5,
        "use_cross_encoder": true,
        "cross_encoder_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "hybrid_alpha": 0.5,
        "expected_improvement": "+40-50%",
        "rationale": "Preserves clause and section boundaries"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.5991164475270514,
          "aucroc": null,
          "mean_predicted": 0.2480164200594308,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.12556349355494253,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.13091781943436465,
          "aucroc": null,
          "mean_predicted": 0.1446757344606807,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.11501457891185786,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.5696734968347661,
          "aucroc": null,
          "mean_predicted": 0.5181488801054017,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.35134162205650243,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.2,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.4000000000000001,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp4_semantic_chunking_legalbert",
      "config": {
        "name": "legal_exp4_semantic_chunking_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Semantic chunking with LegalBERT",
        "chunking_strategy": "semantic",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "hybrid",
        "top_k_final": 5,
        "use_cross_encoder": true,
        "cross_encoder_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "hybrid_alpha": 0.5,
        "expected_improvement": "+40-50%",
        "rationale": "Semantic legal boundaries"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.39907996897985737,
          "aucroc": null,
          "mean_predicted": 0.5726948627470471,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.2787482547709927,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.4476789339586181,
          "aucroc": null,
          "mean_predicted": 0.3032748538011696,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.36205388214577544,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.4855912031411271,
          "aucroc": null,
          "mean_predicted": 0.5153846153846153,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.4307692307692308,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.4,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.48989794855663565,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp5_high_recall_legalbert",
      "config": {
        "name": "legal_exp5_high_recall_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "High recall: Find all relevant clauses (10 docs)",
        "chunking_strategy": "paragraph_based",
        "chunk_size": 512,
        "chunk_overlap": 50,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "hybrid",
        "top_k_final": 10,
        "use_cross_encoder": true,
        "cross_encoder_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "hybrid_alpha": 0.5,
        "expected_improvement": "+40-50%",
        "rationale": "Comprehensive clause retrieval for contracts"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.5281085748117276,
          "aucroc": null,
          "mean_predicted": 0.3115202120793402,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.3044386356723131,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.2513563916788668,
          "aucroc": null,
          "mean_predicted": 0.13733691650022273,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.21288950546623328,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.3229904850488461,
          "aucroc": null,
          "mean_predicted": 0.37055791560464457,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.3672716603464224,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.2,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.4000000000000001,
          "std_ground_truth": 0.0
        }
      }
    },
    {
      "experiment": "legal_exp6_larger_chunks_legalbert",
      "config": {
        "name": "legal_exp6_larger_chunks_legalbert",
        "domain": "pubmedqa",
        "subset": "cuad",
        "description": "Larger chunks for complete legal context",
        "chunking_strategy": "paragraph_based",
        "chunk_size": 1024,
        "chunk_overlap": 100,
        "embedding_model": "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "retrieval_type": "hybrid",
        "top_k_final": 5,
        "use_cross_encoder": true,
        "cross_encoder_model": "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "hybrid_alpha": 0.5,
        "expected_improvement": "+35-45%",
        "rationale": "Larger chunks preserve legal context"
      },
      "comparison": {
        "relevance_score": {
          "rmse": 0.570770282195114,
          "aucroc": null,
          "mean_predicted": 0.16668657905217044,
          "mean_ground_truth": 0.40493993993993993,
          "std_predicted": 0.08814108995019986,
          "std_ground_truth": 0.4858864064927407
        },
        "utilization_score": {
          "rmse": 0.11974644028575536,
          "aucroc": null,
          "mean_predicted": 0.1269843458015501,
          "mean_ground_truth": 0.030752798252798252,
          "std_predicted": 0.11506517870368949,
          "std_ground_truth": 0.055401678866711226
        },
        "completeness_score": {
          "rmse": 0.5110613206547603,
          "aucroc": null,
          "mean_predicted": 0.6771428571428572,
          "mean_ground_truth": 0.4,
          "std_predicted": 0.3997550270261189,
          "std_ground_truth": 0.37416573867739417
        },
        "adherence_score": {
          "rmse": null,
          "aucroc": NaN,
          "mean_predicted": 0.6,
          "mean_ground_truth": 1.0,
          "std_predicted": 0.48989794855663565,
          "std_ground_truth": 0.0
        }
      }
    }
  ]
}